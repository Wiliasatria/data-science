# -*- coding: utf-8 -*-
"""Final task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iN9g8gRC-QY_nrD1cqpHZuE0ps7jCqGL
"""

# data processing
import numpy as np
import pandas as pd

# data visualization
import matplotlib.pyplot as plt
import seaborn as sns

# statistics
from scipy import stats
from scipy.stats import chi2_contingency

# others
from google.colab import drive
import io
import os
import warnings
warnings.filterwarnings("ignore")
pd.set_option('display.max_columns', 500)

df = pd.read_csv("/content/sample_data/loan_data_2007_2014.csv")
df.head()

df.shape

"""# **DATA UNDERSTANDING**"""

df.info()

df

# DataFrame untuk menyimpan kolom dan tipe data
df_type = pd.DataFrame({'Columns':df.columns, 'Type':df.dtypes.values})
# Kelompokkan berdasarkan tipe data
df_type = df_type.sort_values(by="Type").reset_index(drop=True)
df_type.index = df_type.index + 1 # Start from 1 index

from tabulate import tabulate
print(tabulate(df_type,headers="keys",tablefmt="grid"))

df.columns

df['Fully Paid'].unique()

df['good_bad']=np.where(df.loc[:,'Fully Paid'].isin(['Charged off','Default','Late(31-120 days)']), 1, 0)

df.good_bad.value_counts()

df[['Fully Paid','good_bad']]

df[df.duplicated()]

# DataFrame untuk menyimpan kolom dan tipe data
df_type = pd.DataFrame({'Columns':df.columns, 'Type':df.dtypes.values})
# Kelompokkan berdasarkan tipe data
df_type = df_type.sort_values(by="Type").reset_index(drop=True)
df_type.index = df_type.index + 1 # Start from 1 index

from tabulate import tabulate
print(tabulate(df_type,headers="keys",tablefmt="grid"))

"""# EXPLORATORY DATA ANALYSIS (EDA)

**Handling** **Missing** **Value**
"""

missing_values= pd.DataFrame(df.isnull().sum()/df.shape[0])
display(missing_values)

missing_values=missing_values[missing_values.iloc[:,0]>0.50]

missing_values.sort_values([0], ascending=False)

df.dropna(thresh=df.shape[0]*0.5, axis=1, inplace=True)

missing_values= pd.DataFrame(df.isnull().sum()/df.shape[0])
display(missing_values)
missing_values= pd.DataFrame(df.isnull().sum()/df.shape[0])
display(missing_values)
missing_values.sort_values([0], ascending=False)

"""**Data** **Splitting**"""

from sklearn.model_selection import train_test_split

# Membagi data menjadi 80/20 dengan menyamakan distribusi dari bad loans di test set dengan train set.
X = df.drop('good_bad', axis=1)
y = df['good_bad']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, stratify= y, random_state=42)

y_train.value_counts(normalize=True)

# Distribusi y_test sudah sama persis dengan y_train
y_test.value_counts(normalize=True)



"""# **DATA CLEANING**"""

X_train.shape

#Dapat dilakukan print untuk semua unique values kolom, sehingga dapat di cek satu-satu
# unique values apa saja yang kotor.

for col in X_train.select_dtypes(include= ['object','bool']).columns:
    print(col)
    print(X_train[col].unique())
    print()

# Kolom/feature yang harus di cleaning
col_need_to_clean = ['term', 'emp_length', 'issue_d', 'earliest_cr_line', 'last_pymnt_d',
                    'next_pymnt_d', 'last_credit_pull_d']

# Menghilangkan ' months' menjadi ''
X_train['term'].str.replace('months', '')

# Cek values apa saja yang harus di cleaning
X_train[' emp_length'].unique()

# Cek feature date
col_date = ['issue_d', 'earliest_cr_line', 'last_pymnt_d',
                    'next_pymnt_d', 'last_credit_pull_d']

X_train[col_date]

df_imputed.isnull().sum()

